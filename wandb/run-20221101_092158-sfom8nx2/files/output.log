
Loaded pretrained weights for efficientnet-b0
/opt/ml/level1_imageclassification_cv-level1-cv-15/model.py:108: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  nn.init.xavier_uniform(self.model.fc.weight)
Epoch[0/10](20/967) || training loss 0.9672 || training accuracy 6.56% || lr 2e-08
Epoch[0/10](40/967) || training loss 0.9681 || training accuracy 8.12% || lr 2e-08
Epoch[0/10](60/967) || training loss 0.9672 || training accuracy 3.44% || lr 2e-08
Epoch[0/10](80/967) || training loss 0.9691 || training accuracy 6.25% || lr 2e-08
Epoch[0/10](100/967) || training loss 0.9682 || training accuracy 5.00% || lr 2e-08
Epoch[0/10](120/967) || training loss 0.9685 || training accuracy 5.31% || lr 2e-08
Epoch[0/10](140/967) || training loss 0.9679 || training accuracy 7.50% || lr 2e-08
Epoch[0/10](160/967) || training loss 0.9681 || training accuracy 5.94% || lr 2e-08
Epoch[0/10](180/967) || training loss 0.9678 || training accuracy 6.88% || lr 2e-08
Epoch[0/10](200/967) || training loss 0.9677 || training accuracy 8.75% || lr 2e-08
Epoch[0/10](220/967) || training loss 0.968 || training accuracy 7.19% || lr 2e-08
Epoch[0/10](240/967) || training loss 0.9694 || training accuracy 7.19% || lr 2e-08
Epoch[0/10](260/967) || training loss 0.9676 || training accuracy 5.31% || lr 2e-08
Epoch[0/10](280/967) || training loss 0.9678 || training accuracy 7.50% || lr 2e-08
Epoch[0/10](300/967) || training loss 0.9707 || training accuracy 6.56% || lr 2e-08
Epoch[0/10](320/967) || training loss 0.9675 || training accuracy 4.69% || lr 2e-08
Epoch[0/10](340/967) || training loss 0.97 || training accuracy 6.88% || lr 2e-08
Epoch[0/10](360/967) || training loss 0.9685 || training accuracy 5.62% || lr 2e-08
Epoch[0/10](380/967) || training loss 0.9675 || training accuracy 5.00% || lr 2e-08
Epoch[0/10](400/967) || training loss 0.9678 || training accuracy 5.31% || lr 2e-08
Epoch[0/10](420/967) || training loss 0.9682 || training accuracy 5.62% || lr 2e-08
Epoch[0/10](440/967) || training loss 0.9687 || training accuracy 3.12% || lr 2e-08
Epoch[0/10](460/967) || training loss 0.9677 || training accuracy 4.06% || lr 2e-08
Epoch[0/10](480/967) || training loss 0.969 || training accuracy 5.94% || lr 2e-08
Epoch[0/10](500/967) || training loss 0.9691 || training accuracy 5.31% || lr 2e-08
Epoch[0/10](520/967) || training loss 0.9693 || training accuracy 6.25% || lr 2e-08
Epoch[0/10](540/967) || training loss 0.9695 || training accuracy 5.00% || lr 2e-08
Epoch[0/10](560/967) || training loss 0.9688 || training accuracy 5.62% || lr 2e-08
Epoch[0/10](580/967) || training loss 0.9682 || training accuracy 6.56% || lr 2e-08
Epoch[0/10](600/967) || training loss 0.9688 || training accuracy 3.12% || lr 2e-08
Epoch[0/10](620/967) || training loss 0.9695 || training accuracy 4.06% || lr 2e-08
Epoch[0/10](640/967) || training loss 0.9688 || training accuracy 4.38% || lr 2e-08
Epoch[0/10](660/967) || training loss 0.969 || training accuracy 4.06% || lr 2e-08
Epoch[0/10](680/967) || training loss 0.9675 || training accuracy 5.94% || lr 2e-08
Epoch[0/10](700/967) || training loss 0.9686 || training accuracy 5.62% || lr 2e-08
Epoch[0/10](720/967) || training loss 0.9688 || training accuracy 7.81% || lr 2e-08
Epoch[0/10](740/967) || training loss 0.9694 || training accuracy 5.94% || lr 2e-08
Epoch[0/10](760/967) || training loss 0.968 || training accuracy 5.31% || lr 2e-08
Epoch[0/10](780/967) || training loss 0.9692 || training accuracy 4.38% || lr 2e-08
Epoch[0/10](800/967) || training loss 0.9696 || training accuracy 5.00% || lr 2e-08
Epoch[0/10](820/967) || training loss 0.9693 || training accuracy 6.25% || lr 2e-08
Epoch[0/10](840/967) || training loss 0.9669 || training accuracy 4.06% || lr 2e-08
Epoch[0/10](860/967) || training loss 0.9675 || training accuracy 2.81% || lr 2e-08
Epoch[0/10](880/967) || training loss 0.97 || training accuracy 5.94% || lr 2e-08
Epoch[0/10](900/967) || training loss 0.9678 || training accuracy 4.69% || lr 2e-08
Epoch[0/10](920/967) || training loss 0.9672 || training accuracy 4.06% || lr 2e-08
Epoch[0/10](940/967) || training loss 0.9681 || training accuracy 5.62% || lr 2e-08
Epoch[0/10](960/967) || training loss 0.9698 || training accuracy 6.88% || lr 2e-08
Calculating validation results...
New best model for val accuracy in epoch 0: 5.42%! saving the best model..
[Val] acc : 5.42%, loss: 0.96 || best acc : 5.42%, best loss: 0.96
Epoch[1/10](20/967) || training loss 0.9702 || training accuracy 6.25% || lr 4.016e-06
Epoch[1/10](40/967) || training loss 0.968 || training accuracy 10.31% || lr 4.016e-06
Epoch[1/10](60/967) || training loss 0.9677 || training accuracy 7.81% || lr 4.016e-06
Epoch[1/10](80/967) || training loss 0.9685 || training accuracy 8.12% || lr 4.016e-06
Epoch[1/10](100/967) || training loss 0.9679 || training accuracy 7.50% || lr 4.016e-06
Epoch[1/10](120/967) || training loss 0.9663 || training accuracy 8.75% || lr 4.016e-06
Epoch[1/10](140/967) || training loss 0.9667 || training accuracy 8.12% || lr 4.016e-06
Epoch[1/10](160/967) || training loss 0.9671 || training accuracy 8.44% || lr 4.016e-06
Epoch[1/10](180/967) || training loss 0.9683 || training accuracy 12.81% || lr 4.016e-06
Epoch[1/10](200/967) || training loss 0.9679 || training accuracy 10.31% || lr 4.016e-06
Epoch[1/10](220/967) || training loss 0.9654 || training accuracy 11.25% || lr 4.016e-06
Epoch[1/10](240/967) || training loss 0.9679 || training accuracy 12.50% || lr 4.016e-06
Epoch[1/10](260/967) || training loss 0.9639 || training accuracy 17.81% || lr 4.016e-06
Epoch[1/10](280/967) || training loss 0.966 || training accuracy 13.12% || lr 4.016e-06
Epoch[1/10](300/967) || training loss 0.9641 || training accuracy 16.56% || lr 4.016e-06
Epoch[1/10](320/967) || training loss 0.9646 || training accuracy 20.62% || lr 4.016e-06
Epoch[1/10](340/967) || training loss 0.9627 || training accuracy 16.56% || lr 4.016e-06
Epoch[1/10](360/967) || training loss 0.9646 || training accuracy 18.44% || lr 4.016e-06
Epoch[1/10](380/967) || training loss 0.9649 || training accuracy 20.62% || lr 4.016e-06
Epoch[1/10](400/967) || training loss 0.9631 || training accuracy 22.50% || lr 4.016e-06
Epoch[1/10](420/967) || training loss 0.9633 || training accuracy 23.75% || lr 4.016e-06
Epoch[1/10](440/967) || training loss 0.9649 || training accuracy 21.56% || lr 4.016e-06
Epoch[1/10](460/967) || training loss 0.963 || training accuracy 26.25% || lr 4.016e-06
Epoch[1/10](480/967) || training loss 0.963 || training accuracy 29.06% || lr 4.016e-06
Epoch[1/10](500/967) || training loss 0.9641 || training accuracy 29.69% || lr 4.016e-06
Epoch[1/10](520/967) || training loss 0.9607 || training accuracy 28.75% || lr 4.016e-06
Epoch[1/10](540/967) || training loss 0.9623 || training accuracy 29.69% || lr 4.016e-06
Epoch[1/10](560/967) || training loss 0.9609 || training accuracy 29.69% || lr 4.016e-06
Epoch[1/10](580/967) || training loss 0.9608 || training accuracy 32.19% || lr 4.016e-06
Epoch[1/10](600/967) || training loss 0.9623 || training accuracy 33.75% || lr 4.016e-06
Epoch[1/10](620/967) || training loss 0.9599 || training accuracy 30.31% || lr 4.016e-06
Epoch[1/10](640/967) || training loss 0.9611 || training accuracy 33.12% || lr 4.016e-06
Epoch[1/10](660/967) || training loss 0.9586 || training accuracy 30.63% || lr 4.016e-06
Epoch[1/10](680/967) || training loss 0.962 || training accuracy 33.75% || lr 4.016e-06
Epoch[1/10](700/967) || training loss 0.9586 || training accuracy 35.62% || lr 4.016e-06
Epoch[1/10](720/967) || training loss 0.9578 || training accuracy 36.56% || lr 4.016e-06
Epoch[1/10](740/967) || training loss 0.959 || training accuracy 42.81% || lr 4.016e-06
Epoch[1/10](760/967) || training loss 0.9599 || training accuracy 35.31% || lr 4.016e-06
Epoch[1/10](780/967) || training loss 0.9573 || training accuracy 39.06% || lr 4.016e-06
Epoch[1/10](800/967) || training loss 0.9591 || training accuracy 43.44% || lr 4.016e-06
Epoch[1/10](820/967) || training loss 0.9553 || training accuracy 40.62% || lr 4.016e-06
Epoch[1/10](840/967) || training loss 0.956 || training accuracy 47.81% || lr 4.016e-06
Epoch[1/10](860/967) || training loss 0.9526 || training accuracy 45.62% || lr 4.016e-06
Epoch[1/10](880/967) || training loss 0.956 || training accuracy 36.88% || lr 4.016e-06
Epoch[1/10](900/967) || training loss 0.9544 || training accuracy 46.56% || lr 4.016e-06
Epoch[1/10](920/967) || training loss 0.9532 || training accuracy 42.81% || lr 4.016e-06
Epoch[1/10](940/967) || training loss 0.9547 || training accuracy 45.94% || lr 4.016e-06
Epoch[1/10](960/967) || training loss 0.9518 || training accuracy 48.12% || lr 4.016e-06
Calculating validation results...
New best model for val accuracy in epoch 1: 50.53%! saving the best model..
[Val] acc : 50.53%, loss: 0.94 || best acc : 50.53%, best loss: 0.94
Epoch[2/10](20/967) || training loss 0.9484 || training accuracy 43.44% || lr 8.012e-06
Epoch[2/10](40/967) || training loss 0.9479 || training accuracy 42.19% || lr 8.012e-06
Epoch[2/10](60/967) || training loss 0.947 || training accuracy 45.62% || lr 8.012e-06
Epoch[2/10](80/967) || training loss 0.9457 || training accuracy 47.81% || lr 8.012e-06
Epoch[2/10](100/967) || training loss 0.94 || training accuracy 49.38% || lr 8.012e-06
Epoch[2/10](120/967) || training loss 0.9365 || training accuracy 44.69% || lr 8.012e-06
Epoch[2/10](140/967) || training loss 0.9347 || training accuracy 51.88% || lr 8.012e-06
Epoch[2/10](160/967) || training loss 0.9353 || training accuracy 55.62% || lr 8.012e-06
Epoch[2/10](180/967) || training loss 0.9314 || training accuracy 57.19% || lr 8.012e-06
Epoch[2/10](200/967) || training loss 0.9233 || training accuracy 50.62% || lr 8.012e-06
Epoch[2/10](220/967) || training loss 0.9255 || training accuracy 50.62% || lr 8.012e-06
Epoch[2/10](240/967) || training loss 0.9199 || training accuracy 51.56% || lr 8.012e-06
Epoch[2/10](260/967) || training loss 0.9163 || training accuracy 55.94% || lr 8.012e-06
Epoch[2/10](280/967) || training loss 0.9137 || training accuracy 59.69% || lr 8.012e-06
Epoch[2/10](300/967) || training loss 0.9021 || training accuracy 58.75% || lr 8.012e-06
Epoch[2/10](320/967) || training loss 0.909 || training accuracy 60.00% || lr 8.012e-06
Epoch[2/10](340/967) || training loss 0.9039 || training accuracy 54.69% || lr 8.012e-06
Epoch[2/10](360/967) || training loss 0.8986 || training accuracy 55.00% || lr 8.012e-06
Epoch[2/10](380/967) || training loss 0.8939 || training accuracy 60.94% || lr 8.012e-06
Epoch[2/10](400/967) || training loss 0.8862 || training accuracy 61.56% || lr 8.012e-06
Epoch[2/10](420/967) || training loss 0.8909 || training accuracy 62.81% || lr 8.012e-06
Epoch[2/10](440/967) || training loss 0.8942 || training accuracy 64.69% || lr 8.012e-06
Epoch[2/10](460/967) || training loss 0.895 || training accuracy 62.19% || lr 8.012e-06
Epoch[2/10](480/967) || training loss 0.8842 || training accuracy 60.62% || lr 8.012e-06
Epoch[2/10](500/967) || training loss 0.8808 || training accuracy 65.00% || lr 8.012e-06
Epoch[2/10](520/967) || training loss 0.8792 || training accuracy 58.13% || lr 8.012e-06
Epoch[2/10](540/967) || training loss 0.8713 || training accuracy 60.00% || lr 8.012e-06
Epoch[2/10](560/967) || training loss 0.8737 || training accuracy 60.31% || lr 8.012e-06
Epoch[2/10](580/967) || training loss 0.8766 || training accuracy 66.56% || lr 8.012e-06
Epoch[2/10](600/967) || training loss 0.8719 || training accuracy 65.62% || lr 8.012e-06
Epoch[2/10](620/967) || training loss 0.8576 || training accuracy 67.50% || lr 8.012e-06
Epoch[2/10](640/967) || training loss 0.8554 || training accuracy 66.56% || lr 8.012e-06
Epoch[2/10](660/967) || training loss 0.8557 || training accuracy 67.19% || lr 8.012e-06
Epoch[2/10](680/967) || training loss 0.8647 || training accuracy 68.12% || lr 8.012e-06
Epoch[2/10](700/967) || training loss 0.8468 || training accuracy 69.06% || lr 8.012e-06
Epoch[2/10](720/967) || training loss 0.8539 || training accuracy 60.94% || lr 8.012e-06
Epoch[2/10](740/967) || training loss 0.8466 || training accuracy 70.00% || lr 8.012e-06
Epoch[2/10](760/967) || training loss 0.854 || training accuracy 66.25% || lr 8.012e-06
Epoch[2/10](780/967) || training loss 0.842 || training accuracy 65.31% || lr 8.012e-06
Epoch[2/10](800/967) || training loss 0.8413 || training accuracy 65.00% || lr 8.012e-06
Epoch[2/10](820/967) || training loss 0.8419 || training accuracy 65.00% || lr 8.012e-06
Epoch[2/10](840/967) || training loss 0.8402 || training accuracy 69.38% || lr 8.012e-06
Epoch[2/10](860/967) || training loss 0.8307 || training accuracy 64.06% || lr 8.012e-06
Epoch[2/10](880/967) || training loss 0.8392 || training accuracy 70.00% || lr 8.012e-06
Epoch[2/10](900/967) || training loss 0.8293 || training accuracy 71.88% || lr 8.012e-06
Epoch[2/10](920/967) || training loss 0.8344 || training accuracy 67.81% || lr 8.012e-06
Epoch[2/10](940/967) || training loss 0.8176 || training accuracy 68.75% || lr 8.012e-06
Epoch[2/10](960/967) || training loss 0.8241 || training accuracy 68.75% || lr 8.012e-06
Calculating validation results...
New best model for val accuracy in epoch 2: 72.72%! saving the best model..
[Val] acc : 72.72%, loss: 0.78 || best acc : 72.72%, best loss: 0.78
Epoch[3/10](20/967) || training loss 0.82 || training accuracy 69.06% || lr 1.2008000000000001e-05
Epoch[3/10](40/967) || training loss 0.8106 || training accuracy 74.69% || lr 1.2008000000000001e-05
Epoch[3/10](60/967) || training loss 0.8092 || training accuracy 72.19% || lr 1.2008000000000001e-05
Epoch[3/10](80/967) || training loss 0.8002 || training accuracy 75.62% || lr 1.2008000000000001e-05
Epoch[3/10](100/967) || training loss 0.8186 || training accuracy 69.38% || lr 1.2008000000000001e-05
Epoch[3/10](120/967) || training loss 0.8025 || training accuracy 73.44% || lr 1.2008000000000001e-05
Epoch[3/10](140/967) || training loss 0.8037 || training accuracy 74.06% || lr 1.2008000000000001e-05
Epoch[3/10](160/967) || training loss 0.806 || training accuracy 69.69% || lr 1.2008000000000001e-05
Epoch[3/10](180/967) || training loss 0.7832 || training accuracy 74.38% || lr 1.2008000000000001e-05
Epoch[3/10](200/967) || training loss 0.7945 || training accuracy 66.56% || lr 1.2008000000000001e-05
Epoch[3/10](220/967) || training loss 0.7924 || training accuracy 69.38% || lr 1.2008000000000001e-05
Epoch[3/10](240/967) || training loss 0.7842 || training accuracy 74.06% || lr 1.2008000000000001e-05
Epoch[3/10](260/967) || training loss 0.7638 || training accuracy 77.50% || lr 1.2008000000000001e-05
Epoch[3/10](280/967) || training loss 0.7775 || training accuracy 75.62% || lr 1.2008000000000001e-05
Epoch[3/10](300/967) || training loss 0.7677 || training accuracy 71.56% || lr 1.2008000000000001e-05
Epoch[3/10](320/967) || training loss 0.7754 || training accuracy 75.00% || lr 1.2008000000000001e-05
Epoch[3/10](340/967) || training loss 0.7612 || training accuracy 77.50% || lr 1.2008000000000001e-05
Epoch[3/10](360/967) || training loss 0.7667 || training accuracy 75.00% || lr 1.2008000000000001e-05
Epoch[3/10](380/967) || training loss 0.7603 || training accuracy 76.56% || lr 1.2008000000000001e-05
Epoch[3/10](400/967) || training loss 0.7468 || training accuracy 77.19% || lr 1.2008000000000001e-05
Epoch[3/10](420/967) || training loss 0.7537 || training accuracy 79.38% || lr 1.2008000000000001e-05
Epoch[3/10](440/967) || training loss 0.7541 || training accuracy 75.94% || lr 1.2008000000000001e-05
Epoch[3/10](460/967) || training loss 0.7608 || training accuracy 75.62% || lr 1.2008000000000001e-05
Epoch[3/10](480/967) || training loss 0.7514 || training accuracy 70.94% || lr 1.2008000000000001e-05
Epoch[3/10](500/967) || training loss 0.7508 || training accuracy 73.75% || lr 1.2008000000000001e-05
Epoch[3/10](520/967) || training loss 0.7469 || training accuracy 77.19% || lr 1.2008000000000001e-05
Epoch[3/10](540/967) || training loss 0.7384 || training accuracy 76.25% || lr 1.2008000000000001e-05
Epoch[3/10](560/967) || training loss 0.7548 || training accuracy 71.56% || lr 1.2008000000000001e-05
Epoch[3/10](580/967) || training loss 0.7347 || training accuracy 80.62% || lr 1.2008000000000001e-05
Epoch[3/10](600/967) || training loss 0.7281 || training accuracy 80.62% || lr 1.2008000000000001e-05
Epoch[3/10](620/967) || training loss 0.7203 || training accuracy 78.12% || lr 1.2008000000000001e-05
Epoch[3/10](640/967) || training loss 0.7338 || training accuracy 75.94% || lr 1.2008000000000001e-05
Epoch[3/10](660/967) || training loss 0.7259 || training accuracy 81.88% || lr 1.2008000000000001e-05
Epoch[3/10](680/967) || training loss 0.7222 || training accuracy 80.62% || lr 1.2008000000000001e-05
Epoch[3/10](700/967) || training loss 0.7263 || training accuracy 78.12% || lr 1.2008000000000001e-05
Epoch[3/10](720/967) || training loss 0.71 || training accuracy 80.94% || lr 1.2008000000000001e-05
Epoch[3/10](740/967) || training loss 0.7192 || training accuracy 80.00% || lr 1.2008000000000001e-05
Epoch[3/10](760/967) || training loss 0.7315 || training accuracy 77.81% || lr 1.2008000000000001e-05
Epoch[3/10](780/967) || training loss 0.7079 || training accuracy 82.50% || lr 1.2008000000000001e-05
Epoch[3/10](800/967) || training loss 0.7061 || training accuracy 77.81% || lr 1.2008000000000001e-05
Epoch[3/10](820/967) || training loss 0.6941 || training accuracy 80.62% || lr 1.2008000000000001e-05
Epoch[3/10](840/967) || training loss 0.6799 || training accuracy 80.31% || lr 1.2008000000000001e-05
Epoch[3/10](860/967) || training loss 0.7183 || training accuracy 79.06% || lr 1.2008000000000001e-05
Epoch[3/10](880/967) || training loss 0.6993 || training accuracy 78.75% || lr 1.2008000000000001e-05
Epoch[3/10](900/967) || training loss 0.7112 || training accuracy 79.06% || lr 1.2008000000000001e-05
Epoch[3/10](920/967) || training loss 0.7076 || training accuracy 79.69% || lr 1.2008000000000001e-05
Epoch[3/10](940/967) || training loss 0.6979 || training accuracy 79.69% || lr 1.2008000000000001e-05
Epoch[3/10](960/967) || training loss 0.7362 || training accuracy 76.88% || lr 1.2008000000000001e-05
Calculating validation results...
New best model for val accuracy in epoch 3: 82.20%! saving the best model..
[Val] acc : 82.20%, loss: 0.57 || best acc : 82.20%, best loss: 0.57
Epoch[4/10](20/967) || training loss 0.7223 || training accuracy 75.62% || lr 1.6004e-05
Epoch[4/10](40/967) || training loss 0.7153 || training accuracy 76.88% || lr 1.6004e-05
Epoch[4/10](60/967) || training loss 0.7282 || training accuracy 78.75% || lr 1.6004e-05
Epoch[4/10](80/967) || training loss 0.6839 || training accuracy 87.50% || lr 1.6004e-05
Epoch[4/10](100/967) || training loss 0.6938 || training accuracy 80.31% || lr 1.6004e-05
Epoch[4/10](120/967) || training loss 0.7039 || training accuracy 79.38% || lr 1.6004e-05
Epoch[4/10](140/967) || training loss 0.7069 || training accuracy 82.50% || lr 1.6004e-05
Epoch[4/10](160/967) || training loss 0.7007 || training accuracy 81.88% || lr 1.6004e-05
Epoch[4/10](180/967) || training loss 0.7159 || training accuracy 77.81% || lr 1.6004e-05
Epoch[4/10](200/967) || training loss 0.6915 || training accuracy 83.75% || lr 1.6004e-05
Epoch[4/10](220/967) || training loss 0.6707 || training accuracy 86.25% || lr 1.6004e-05
Epoch[4/10](240/967) || training loss 0.6838 || training accuracy 83.12% || lr 1.6004e-05
Epoch[4/10](260/967) || training loss 0.7085 || training accuracy 84.06% || lr 1.6004e-05
Epoch[4/10](280/967) || training loss 0.6726 || training accuracy 82.50% || lr 1.6004e-05
Epoch[4/10](300/967) || training loss 0.6952 || training accuracy 81.88% || lr 1.6004e-05
Epoch[4/10](320/967) || training loss 0.6753 || training accuracy 82.81% || lr 1.6004e-05
Epoch[4/10](340/967) || training loss 0.6964 || training accuracy 83.75% || lr 1.6004e-05
Epoch[4/10](360/967) || training loss 0.6914 || training accuracy 82.81% || lr 1.6004e-05
Epoch[4/10](380/967) || training loss 0.6891 || training accuracy 85.31% || lr 1.6004e-05
Epoch[4/10](400/967) || training loss 0.6736 || training accuracy 86.25% || lr 1.6004e-05
Epoch[4/10](420/967) || training loss 0.6822 || training accuracy 83.12% || lr 1.6004e-05
Epoch[4/10](440/967) || training loss 0.6828 || training accuracy 85.31% || lr 1.6004e-05
Epoch[4/10](460/967) || training loss 0.703 || training accuracy 82.81% || lr 1.6004e-05
Epoch[4/10](480/967) || training loss 0.6664 || training accuracy 80.94% || lr 1.6004e-05
Epoch[4/10](500/967) || training loss 0.6626 || training accuracy 81.88% || lr 1.6004e-05
Epoch[4/10](520/967) || training loss 0.6801 || training accuracy 83.44% || lr 1.6004e-05
Epoch[4/10](540/967) || training loss 0.684 || training accuracy 80.00% || lr 1.6004e-05
Epoch[4/10](560/967) || training loss 0.6686 || training accuracy 84.06% || lr 1.6004e-05
Epoch[4/10](580/967) || training loss 0.677 || training accuracy 82.81% || lr 1.6004e-05
Epoch[4/10](600/967) || training loss 0.6765 || training accuracy 80.31% || lr 1.6004e-05
Epoch[4/10](620/967) || training loss 0.66 || training accuracy 84.38% || lr 1.6004e-05
Epoch[4/10](640/967) || training loss 0.6735 || training accuracy 83.75% || lr 1.6004e-05
Epoch[4/10](660/967) || training loss 0.6825 || training accuracy 82.81% || lr 1.6004e-05
Epoch[4/10](680/967) || training loss 0.6463 || training accuracy 85.00% || lr 1.6004e-05
Epoch[4/10](700/967) || training loss 0.6735 || training accuracy 80.62% || lr 1.6004e-05
Epoch[4/10](720/967) || training loss 0.6783 || training accuracy 85.31% || lr 1.6004e-05
Epoch[4/10](740/967) || training loss 0.647 || training accuracy 84.06% || lr 1.6004e-05
Epoch[4/10](760/967) || training loss 0.6933 || training accuracy 82.50% || lr 1.6004e-05
Epoch[4/10](780/967) || training loss 0.6317 || training accuracy 85.62% || lr 1.6004e-05
Epoch[4/10](800/967) || training loss 0.6772 || training accuracy 80.31% || lr 1.6004e-05
Epoch[4/10](820/967) || training loss 0.6443 || training accuracy 87.19% || lr 1.6004e-05
Epoch[4/10](840/967) || training loss 0.6674 || training accuracy 85.00% || lr 1.6004e-05
Epoch[4/10](860/967) || training loss 0.6218 || training accuracy 87.19% || lr 1.6004e-05
Epoch[4/10](880/967) || training loss 0.6348 || training accuracy 86.25% || lr 1.6004e-05
Epoch[4/10](900/967) || training loss 0.671 || training accuracy 82.19% || lr 1.6004e-05
Epoch[4/10](920/967) || training loss 0.6686 || training accuracy 85.00% || lr 1.6004e-05
Epoch[4/10](940/967) || training loss 0.6633 || training accuracy 85.00% || lr 1.6004e-05
Epoch[4/10](960/967) || training loss 0.6689 || training accuracy 84.38% || lr 1.6004e-05
Calculating validation results...
New best model for val accuracy in epoch 4: 85.66%! saving the best model..
[Val] acc : 85.66%, loss:  0.5 || best acc : 85.66%, best loss:  0.5
Epoch[5/10](20/967) || training loss 0.6385 || training accuracy 85.94% || lr 2e-05
Epoch[5/10](40/967) || training loss 0.6397 || training accuracy 84.69% || lr 2e-05
Epoch[5/10](60/967) || training loss 0.6223 || training accuracy 90.94% || lr 2e-05
Epoch[5/10](80/967) || training loss 0.6425 || training accuracy 86.56% || lr 2e-05
Epoch[5/10](100/967) || training loss 0.6445 || training accuracy 82.19% || lr 2e-05
Epoch[5/10](120/967) || training loss 0.6566 || training accuracy 85.62% || lr 2e-05
Epoch[5/10](140/967) || training loss 0.6467 || training accuracy 86.56% || lr 2e-05
Epoch[5/10](160/967) || training loss 0.6299 || training accuracy 85.94% || lr 2e-05
Epoch[5/10](180/967) || training loss 0.6534 || training accuracy 83.44% || lr 2e-05
Epoch[5/10](200/967) || training loss 0.6506 || training accuracy 85.94% || lr 2e-05
Epoch[5/10](220/967) || training loss 0.629 || training accuracy 87.19% || lr 2e-05
Epoch[5/10](240/967) || training loss 0.687 || training accuracy 84.06% || lr 2e-05
Epoch[5/10](260/967) || training loss 0.6522 || training accuracy 87.19% || lr 2e-05
Epoch[5/10](280/967) || training loss 0.6363 || training accuracy 86.56% || lr 2e-05
Epoch[5/10](300/967) || training loss 0.657 || training accuracy 86.25% || lr 2e-05
Epoch[5/10](320/967) || training loss 0.6566 || training accuracy 86.56% || lr 2e-05
Epoch[5/10](340/967) || training loss 0.6393 || training accuracy 87.81% || lr 2e-05
Epoch[5/10](360/967) || training loss 0.6712 || training accuracy 84.06% || lr 2e-05
Epoch[5/10](380/967) || training loss 0.6357 || training accuracy 87.81% || lr 2e-05
Epoch[5/10](400/967) || training loss 0.6286 || training accuracy 90.62% || lr 2e-05
Epoch[5/10](420/967) || training loss 0.6387 || training accuracy 85.00% || lr 2e-05
Epoch[5/10](440/967) || training loss 0.6106 || training accuracy 88.12% || lr 2e-05
Epoch[5/10](460/967) || training loss 0.6532 || training accuracy 83.12% || lr 2e-05
Epoch[5/10](480/967) || training loss 0.6473 || training accuracy 86.56% || lr 2e-05
Epoch[5/10](500/967) || training loss 0.6638 || training accuracy 83.12% || lr 2e-05
Epoch[5/10](520/967) || training loss 0.6467 || training accuracy 83.12% || lr 2e-05
Epoch[5/10](540/967) || training loss 0.6268 || training accuracy 84.06% || lr 2e-05
Epoch[5/10](560/967) || training loss 0.6467 || training accuracy 88.12% || lr 2e-05
Epoch[5/10](580/967) || training loss 0.6198 || training accuracy 86.88% || lr 2e-05
Epoch[5/10](600/967) || training loss 0.6272 || training accuracy 87.19% || lr 2e-05
Epoch[5/10](620/967) || training loss 0.6485 || training accuracy 85.62% || lr 2e-05
Epoch[5/10](640/967) || training loss 0.6336 || training accuracy 88.44% || lr 2e-05
Epoch[5/10](660/967) || training loss 0.6114 || training accuracy 87.50% || lr 2e-05
Epoch[5/10](680/967) || training loss 0.6513 || training accuracy 86.88% || lr 2e-05
Epoch[5/10](700/967) || training loss 0.6539 || training accuracy 85.31% || lr 2e-05
Epoch[5/10](720/967) || training loss 0.6407 || training accuracy 87.50% || lr 2e-05
Epoch[5/10](740/967) || training loss 0.6386 || training accuracy 88.12% || lr 2e-05
Epoch[5/10](760/967) || training loss 0.6419 || training accuracy 87.50% || lr 2e-05
Epoch[5/10](780/967) || training loss 0.6343 || training accuracy 84.69% || lr 2e-05
Epoch[5/10](800/967) || training loss 0.636 || training accuracy 86.88% || lr 2e-05
Epoch[5/10](820/967) || training loss 0.643 || training accuracy 88.12% || lr 2e-05
Epoch[5/10](840/967) || training loss 0.6406 || training accuracy 85.94% || lr 2e-05
Epoch[5/10](860/967) || training loss 0.6504 || training accuracy 87.19% || lr 2e-05
Epoch[5/10](880/967) || training loss 0.6429 || training accuracy 84.06% || lr 2e-05
Epoch[5/10](900/967) || training loss 0.6289 || training accuracy 85.62% || lr 2e-05
Epoch[5/10](920/967) || training loss 0.6264 || training accuracy 86.25% || lr 2e-05
Epoch[5/10](940/967) || training loss 0.6272 || training accuracy 86.56% || lr 2e-05
Epoch[5/10](960/967) || training loss 0.6513 || training accuracy 84.38% || lr 2e-05
Calculating validation results...
New best model for val accuracy in epoch 5: 87.70%! saving the best model..
[Val] acc : 87.70%, loss: 0.47 || best acc : 87.70%, best loss: 0.47
Epoch[6/10](20/967) || training loss 0.6358 || training accuracy 89.69% || lr 2e-05
Epoch[6/10](40/967) || training loss 0.6363 || training accuracy 87.50% || lr 2e-05
Epoch[6/10](60/967) || training loss 0.5947 || training accuracy 86.88% || lr 2e-05
Epoch[6/10](80/967) || training loss 0.6269 || training accuracy 90.62% || lr 2e-05
Epoch[6/10](100/967) || training loss 0.622 || training accuracy 87.19% || lr 2e-05
Epoch[6/10](120/967) || training loss 0.6578 || training accuracy 85.00% || lr 2e-05
Epoch[6/10](140/967) || training loss 0.6417 || training accuracy 87.19% || lr 2e-05
Epoch[6/10](160/967) || training loss 0.6112 || training accuracy 86.56% || lr 2e-05
Epoch[6/10](180/967) || training loss 0.6322 || training accuracy 88.12% || lr 2e-05
Epoch[6/10](200/967) || training loss 0.616 || training accuracy 87.81% || lr 2e-05
Epoch[6/10](220/967) || training loss 0.6154 || training accuracy 88.12% || lr 2e-05
Epoch[6/10](240/967) || training loss 0.6432 || training accuracy 88.75% || lr 2e-05
Epoch[6/10](260/967) || training loss 0.6344 || training accuracy 86.25% || lr 2e-05
Epoch[6/10](280/967) || training loss 0.6249 || training accuracy 89.06% || lr 2e-05
Epoch[6/10](300/967) || training loss 0.6306 || training accuracy 88.75% || lr 2e-05
Epoch[6/10](320/967) || training loss 0.6162 || training accuracy 90.00% || lr 2e-05
Epoch[6/10](340/967) || training loss 0.6297 || training accuracy 91.25% || lr 2e-05
Epoch[6/10](360/967) || training loss 0.6449 || training accuracy 86.56% || lr 2e-05
Epoch[6/10](380/967) || training loss 0.6443 || training accuracy 87.81% || lr 2e-05
Epoch[6/10](400/967) || training loss 0.6316 || training accuracy 87.81% || lr 2e-05
Epoch[6/10](420/967) || training loss 0.6501 || training accuracy 87.50% || lr 2e-05
Epoch[6/10](440/967) || training loss 0.5973 || training accuracy 89.38% || lr 2e-05
Epoch[6/10](460/967) || training loss 0.6287 || training accuracy 88.44% || lr 2e-05
Epoch[6/10](480/967) || training loss 0.6171 || training accuracy 85.00% || lr 2e-05
Epoch[6/10](500/967) || training loss 0.6307 || training accuracy 87.50% || lr 2e-05
Epoch[6/10](520/967) || training loss 0.6517 || training accuracy 85.94% || lr 2e-05
Epoch[6/10](540/967) || training loss 0.6138 || training accuracy 86.56% || lr 2e-05
Epoch[6/10](560/967) || training loss 0.6039 || training accuracy 90.31% || lr 2e-05
Epoch[6/10](580/967) || training loss 0.6346 || training accuracy 88.75% || lr 2e-05
Epoch[6/10](600/967) || training loss 0.6355 || training accuracy 86.25% || lr 2e-05
Epoch[6/10](620/967) || training loss 0.6239 || training accuracy 86.56% || lr 2e-05
Epoch[6/10](640/967) || training loss 0.6239 || training accuracy 88.44% || lr 2e-05
Epoch[6/10](660/967) || training loss 0.6329 || training accuracy 87.81% || lr 2e-05
Epoch[6/10](680/967) || training loss 0.5966 || training accuracy 86.56% || lr 2e-05
Epoch[6/10](700/967) || training loss 0.6397 || training accuracy 88.44% || lr 2e-05
Epoch[6/10](720/967) || training loss 0.6346 || training accuracy 90.31% || lr 2e-05
Epoch[6/10](740/967) || training loss 0.6261 || training accuracy 89.69% || lr 2e-05
Epoch[6/10](760/967) || training loss 0.6236 || training accuracy 87.81% || lr 2e-05
Epoch[6/10](780/967) || training loss 0.6561 || training accuracy 84.38% || lr 2e-05
Epoch[6/10](800/967) || training loss 0.6003 || training accuracy 91.25% || lr 2e-05
Epoch[6/10](820/967) || training loss 0.6252 || training accuracy 88.75% || lr 2e-05
Epoch[6/10](840/967) || training loss 0.6476 || training accuracy 85.94% || lr 2e-05
Epoch[6/10](860/967) || training loss 0.6173 || training accuracy 90.94% || lr 2e-05
Epoch[6/10](880/967) || training loss 0.6457 || training accuracy 88.75% || lr 2e-05
Epoch[6/10](900/967) || training loss 0.6282 || training accuracy 86.25% || lr 2e-05
Epoch[6/10](920/967) || training loss 0.6377 || training accuracy 85.00% || lr 2e-05
Epoch[6/10](940/967) || training loss 0.6268 || training accuracy 88.75% || lr 2e-05
Epoch[6/10](960/967) || training loss 0.6166 || training accuracy 90.31% || lr 2e-05
Calculating validation results...
[Val] acc : 87.41%, loss: 0.47 || best acc : 87.70%, best loss: 0.47
Epoch[7/10](20/967) || training loss 0.6544 || training accuracy 86.88% || lr 2e-05
Epoch[7/10](40/967) || training loss 0.6172 || training accuracy 88.44% || lr 2e-05
Epoch[7/10](60/967) || training loss 0.5889 || training accuracy 89.06% || lr 2e-05
Epoch[7/10](80/967) || training loss 0.6194 || training accuracy 89.38% || lr 2e-05
Epoch[7/10](100/967) || training loss 0.6062 || training accuracy 88.12% || lr 2e-05
Epoch[7/10](120/967) || training loss 0.6194 || training accuracy 90.00% || lr 2e-05
Epoch[7/10](140/967) || training loss 0.6526 || training accuracy 86.25% || lr 2e-05
Epoch[7/10](160/967) || training loss 0.6234 || training accuracy 88.12% || lr 2e-05
Epoch[7/10](180/967) || training loss 0.6007 || training accuracy 88.12% || lr 2e-05
Epoch[7/10](200/967) || training loss 0.6619 || training accuracy 86.25% || lr 2e-05
Epoch[7/10](220/967) || training loss 0.6048 || training accuracy 90.62% || lr 2e-05
Epoch[7/10](240/967) || training loss 0.6131 || training accuracy 90.00% || lr 2e-05
Epoch[7/10](260/967) || training loss 0.6219 || training accuracy 88.12% || lr 2e-05
Epoch[7/10](280/967) || training loss 0.6011 || training accuracy 89.06% || lr 2e-05
Epoch[7/10](300/967) || training loss 0.6272 || training accuracy 89.69% || lr 2e-05
Epoch[7/10](320/967) || training loss 0.603 || training accuracy 90.00% || lr 2e-05
Epoch[7/10](340/967) || training loss 0.635 || training accuracy 89.38% || lr 2e-05
Epoch[7/10](360/967) || training loss 0.6109 || training accuracy 89.69% || lr 2e-05
Epoch[7/10](380/967) || training loss 0.6208 || training accuracy 87.81% || lr 2e-05
Epoch[7/10](400/967) || training loss 0.6435 || training accuracy 89.38% || lr 2e-05
Epoch[7/10](420/967) || training loss 0.6038 || training accuracy 90.94% || lr 2e-05
Epoch[7/10](440/967) || training loss 0.6299 || training accuracy 88.44% || lr 2e-05
Epoch[7/10](460/967) || training loss 0.6373 || training accuracy 89.69% || lr 2e-05
Epoch[7/10](480/967) || training loss 0.6077 || training accuracy 90.94% || lr 2e-05
Epoch[7/10](500/967) || training loss 0.6257 || training accuracy 89.69% || lr 2e-05
Epoch[7/10](520/967) || training loss 0.6054 || training accuracy 90.31% || lr 2e-05
Epoch[7/10](540/967) || training loss 0.6255 || training accuracy 88.12% || lr 2e-05
Epoch[7/10](560/967) || training loss 0.5933 || training accuracy 92.19% || lr 2e-05
Epoch[7/10](580/967) || training loss 0.6362 || training accuracy 87.19% || lr 2e-05
Epoch[7/10](600/967) || training loss 0.6138 || training accuracy 89.69% || lr 2e-05
Epoch[7/10](620/967) || training loss 0.6354 || training accuracy 88.12% || lr 2e-05
Epoch[7/10](640/967) || training loss 0.6546 || training accuracy 86.25% || lr 2e-05
Epoch[7/10](660/967) || training loss 0.6234 || training accuracy 90.31% || lr 2e-05
Epoch[7/10](680/967) || training loss 0.614 || training accuracy 87.81% || lr 2e-05
Epoch[7/10](700/967) || training loss 0.6199 || training accuracy 89.06% || lr 2e-05
Epoch[7/10](720/967) || training loss 0.6115 || training accuracy 90.00% || lr 2e-05
Epoch[7/10](740/967) || training loss 0.63 || training accuracy 85.94% || lr 2e-05
Epoch[7/10](760/967) || training loss 0.6191 || training accuracy 89.69% || lr 2e-05
Epoch[7/10](780/967) || training loss 0.6173 || training accuracy 89.38% || lr 2e-05
Epoch[7/10](800/967) || training loss 0.6218 || training accuracy 89.06% || lr 2e-05
Epoch[7/10](820/967) || training loss 0.6062 || training accuracy 90.00% || lr 2e-05
Epoch[7/10](840/967) || training loss 0.5997 || training accuracy 93.44% || lr 2e-05
Epoch[7/10](860/967) || training loss 0.6306 || training accuracy 89.06% || lr 2e-05
Epoch[7/10](880/967) || training loss 0.6026 || training accuracy 90.62% || lr 2e-05
Epoch[7/10](900/967) || training loss 0.6322 || training accuracy 92.19% || lr 2e-05
Epoch[7/10](920/967) || training loss 0.5974 || training accuracy 91.88% || lr 2e-05
Epoch[7/10](940/967) || training loss 0.5968 || training accuracy 91.56% || lr 2e-05
Epoch[7/10](960/967) || training loss 0.6182 || training accuracy 92.50% || lr 2e-05
Calculating validation results...
[Val] acc : 86.53%, loss: 0.47 || best acc : 87.70%, best loss: 0.47
Epoch[8/10](20/967) || training loss 0.6188 || training accuracy 89.06% || lr 2e-05
Epoch[8/10](40/967) || training loss 0.5906 || training accuracy 87.50% || lr 2e-05
Epoch[8/10](60/967) || training loss 0.6152 || training accuracy 88.12% || lr 2e-05
Epoch[8/10](80/967) || training loss 0.6485 || training accuracy 86.88% || lr 2e-05
Epoch[8/10](100/967) || training loss 0.6321 || training accuracy 89.38% || lr 2e-05
Epoch[8/10](120/967) || training loss 0.5865 || training accuracy 92.81% || lr 2e-05
Epoch[8/10](140/967) || training loss 0.5999 || training accuracy 91.56% || lr 2e-05
Epoch[8/10](160/967) || training loss 0.6379 || training accuracy 88.44% || lr 2e-05
Epoch[8/10](180/967) || training loss 0.6229 || training accuracy 90.00% || lr 2e-05
Epoch[8/10](200/967) || training loss 0.5709 || training accuracy 91.56% || lr 2e-05
Epoch[8/10](220/967) || training loss 0.6126 || training accuracy 89.69% || lr 2e-05
Epoch[8/10](240/967) || training loss 0.6239 || training accuracy 89.38% || lr 2e-05
Epoch[8/10](260/967) || training loss 0.6047 || training accuracy 91.25% || lr 2e-05
Epoch[8/10](280/967) || training loss 0.6051 || training accuracy 92.81% || lr 2e-05
Epoch[8/10](300/967) || training loss 0.6132 || training accuracy 88.75% || lr 2e-05
Epoch[8/10](320/967) || training loss 0.644 || training accuracy 87.81% || lr 2e-05
Epoch[8/10](340/967) || training loss 0.5984 || training accuracy 92.81% || lr 2e-05
Epoch[8/10](360/967) || training loss 0.6228 || training accuracy 90.00% || lr 2e-05
Epoch[8/10](380/967) || training loss 0.6137 || training accuracy 88.44% || lr 2e-05
Epoch[8/10](400/967) || training loss 0.6277 || training accuracy 87.81% || lr 2e-05
Epoch[8/10](420/967) || training loss 0.6373 || training accuracy 85.00% || lr 2e-05
Epoch[8/10](440/967) || training loss 0.6049 || training accuracy 92.19% || lr 2e-05
Epoch[8/10](460/967) || training loss 0.6391 || training accuracy 87.50% || lr 2e-05
Epoch[8/10](480/967) || training loss 0.5883 || training accuracy 89.06% || lr 2e-05
Epoch[8/10](500/967) || training loss 0.6089 || training accuracy 90.94% || lr 2e-05
Epoch[8/10](520/967) || training loss 0.6108 || training accuracy 91.25% || lr 2e-05
Epoch[8/10](540/967) || training loss 0.5881 || training accuracy 93.12% || lr 2e-05
Epoch[8/10](560/967) || training loss 0.6511 || training accuracy 86.56% || lr 2e-05
Epoch[8/10](580/967) || training loss 0.6228 || training accuracy 90.31% || lr 2e-05
Epoch[8/10](600/967) || training loss 0.6254 || training accuracy 90.62% || lr 2e-05
Epoch[8/10](620/967) || training loss 0.6183 || training accuracy 90.94% || lr 2e-05
Epoch[8/10](640/967) || training loss 0.5889 || training accuracy 91.56% || lr 2e-05
Epoch[8/10](660/967) || training loss 0.5989 || training accuracy 90.94% || lr 2e-05
Epoch[8/10](680/967) || training loss 0.62 || training accuracy 91.56% || lr 2e-05
Epoch[8/10](700/967) || training loss 0.6109 || training accuracy 90.00% || lr 2e-05
Epoch[8/10](720/967) || training loss 0.6073 || training accuracy 90.31% || lr 2e-05
Epoch[8/10](740/967) || training loss 0.6241 || training accuracy 89.38% || lr 2e-05
Epoch[8/10](760/967) || training loss 0.6142 || training accuracy 90.00% || lr 2e-05
Epoch[8/10](780/967) || training loss 0.6291 || training accuracy 88.12% || lr 2e-05
Epoch[8/10](800/967) || training loss 0.5805 || training accuracy 90.31% || lr 2e-05
Epoch[8/10](820/967) || training loss 0.6026 || training accuracy 90.62% || lr 2e-05
Epoch[8/10](840/967) || training loss 0.6379 || training accuracy 90.00% || lr 2e-05
Epoch[8/10](860/967) || training loss 0.6113 || training accuracy 94.38% || lr 2e-05
Epoch[8/10](880/967) || training loss 0.614 || training accuracy 90.00% || lr 2e-05
Epoch[8/10](900/967) || training loss 0.5892 || training accuracy 93.12% || lr 2e-05
Epoch[8/10](920/967) || training loss 0.6423 || training accuracy 89.69% || lr 2e-05
Epoch[8/10](940/967) || training loss 0.5952 || training accuracy 91.56% || lr 2e-05
Epoch[8/10](960/967) || training loss 0.5848 || training accuracy 90.00% || lr 2e-05
Calculating validation results...
[Val] acc : 87.12%, loss: 0.47 || best acc : 87.70%, best loss: 0.47
Epoch[9/10](20/967) || training loss 0.5964 || training accuracy 90.94% || lr 2e-05
Epoch[9/10](40/967) || training loss 0.6309 || training accuracy 87.50% || lr 2e-05
Epoch[9/10](60/967) || training loss 0.6063 || training accuracy 90.31% || lr 2e-05
Epoch[9/10](80/967) || training loss 0.5816 || training accuracy 95.00% || lr 2e-05
Epoch[9/10](100/967) || training loss 0.6475 || training accuracy 91.56% || lr 2e-05
Epoch[9/10](120/967) || training loss 0.6068 || training accuracy 91.56% || lr 2e-05
Epoch[9/10](140/967) || training loss 0.6129 || training accuracy 91.25% || lr 2e-05
Epoch[9/10](160/967) || training loss 0.5826 || training accuracy 92.19% || lr 2e-05
Epoch[9/10](180/967) || training loss 0.5954 || training accuracy 89.38% || lr 2e-05
Epoch[9/10](200/967) || training loss 0.6094 || training accuracy 90.62% || lr 2e-05
Epoch[9/10](220/967) || training loss 0.6057 || training accuracy 88.12% || lr 2e-05
Epoch[9/10](240/967) || training loss 0.5921 || training accuracy 93.12% || lr 2e-05
Epoch[9/10](260/967) || training loss 0.5967 || training accuracy 90.00% || lr 2e-05
Epoch[9/10](280/967) || training loss 0.6092 || training accuracy 87.81% || lr 2e-05
Epoch[9/10](300/967) || training loss 0.6004 || training accuracy 92.50% || lr 2e-05
Epoch[9/10](320/967) || training loss 0.5895 || training accuracy 90.94% || lr 2e-05
Epoch[9/10](340/967) || training loss 0.6172 || training accuracy 90.94% || lr 2e-05
Epoch[9/10](360/967) || training loss 0.6078 || training accuracy 90.94% || lr 2e-05
Epoch[9/10](380/967) || training loss 0.6073 || training accuracy 91.56% || lr 2e-05
Epoch[9/10](400/967) || training loss 0.6015 || training accuracy 90.31% || lr 2e-05
Epoch[9/10](420/967) || training loss 0.5921 || training accuracy 91.25% || lr 2e-05
Epoch[9/10](440/967) || training loss 0.6138 || training accuracy 94.38% || lr 2e-05
Epoch[9/10](460/967) || training loss 0.568 || training accuracy 91.25% || lr 2e-05
Epoch[9/10](480/967) || training loss 0.624 || training accuracy 89.69% || lr 2e-05
Epoch[9/10](500/967) || training loss 0.6082 || training accuracy 94.06% || lr 2e-05
Epoch[9/10](520/967) || training loss 0.5946 || training accuracy 90.00% || lr 2e-05
Epoch[9/10](540/967) || training loss 0.5598 || training accuracy 95.31% || lr 2e-05
Epoch[9/10](560/967) || training loss 0.5838 || training accuracy 91.56% || lr 2e-05
Epoch[9/10](580/967) || training loss 0.6078 || training accuracy 94.06% || lr 2e-05
Epoch[9/10](600/967) || training loss 0.5912 || training accuracy 93.12% || lr 2e-05
Epoch[9/10](620/967) || training loss 0.6082 || training accuracy 89.38% || lr 2e-05
Epoch[9/10](640/967) || training loss 0.6229 || training accuracy 89.38% || lr 2e-05
Epoch[9/10](660/967) || training loss 0.6123 || training accuracy 88.75% || lr 2e-05
Epoch[9/10](680/967) || training loss 0.5867 || training accuracy 92.81% || lr 2e-05
Epoch[9/10](700/967) || training loss 0.587 || training accuracy 93.75% || lr 2e-05
Epoch[9/10](720/967) || training loss 0.6115 || training accuracy 91.56% || lr 2e-05
Epoch[9/10](740/967) || training loss 0.6299 || training accuracy 91.88% || lr 2e-05
Epoch[9/10](760/967) || training loss 0.608 || training accuracy 90.62% || lr 2e-05
Epoch[9/10](780/967) || training loss 0.6103 || training accuracy 91.88% || lr 2e-05
Epoch[9/10](800/967) || training loss 0.6088 || training accuracy 90.31% || lr 2e-05
Epoch[9/10](820/967) || training loss 0.5712 || training accuracy 94.06% || lr 2e-05
Epoch[9/10](840/967) || training loss 0.591 || training accuracy 93.75% || lr 2e-05
Epoch[9/10](860/967) || training loss 0.6124 || training accuracy 91.56% || lr 2e-05
Epoch[9/10](880/967) || training loss 0.606 || training accuracy 91.25% || lr 2e-05
Epoch[9/10](900/967) || training loss 0.6171 || training accuracy 90.31% || lr 2e-05
Epoch[9/10](920/967) || training loss 0.6167 || training accuracy 90.62% || lr 2e-05
Epoch[9/10](940/967) || training loss 0.6495 || training accuracy 87.19% || lr 2e-05
Epoch[9/10](960/967) || training loss 0.5882 || training accuracy 92.81% || lr 2e-05
Calculating validation results...
[Val] acc : 87.38%, loss: 0.46 || best acc : 87.70%, best loss: 0.46